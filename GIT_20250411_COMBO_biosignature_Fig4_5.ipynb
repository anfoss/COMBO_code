{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import joblib\n",
    "\n",
    "\n",
    "def parse_input():\n",
    "    dd = pd.ExcelFile('meta/COMBO PRO Banked Samples Aliquot Clinical Data.xlsx')\n",
    "    kk = []\n",
    "    for x in dd.sheet_names:\n",
    "        tmp = pd.read_excel('meta/COMBO PRO Banked Samples Aliquot Clinical Data.xlsx', sheet_name=x)\n",
    "        tmp['loc'] = x\n",
    "        kk.append(tmp)\n",
    "    tot = pd.concat(kk)\n",
    "    return tot\n",
    "\n",
    "\n",
    "def preprocess_metadata(flt):\n",
    "    cols = \"#E64B35B2\", \"#4DBBD5B2\", \"#00A087B2\", \"#3C5488B2\", \"#F39B7FB2\", \"#8491B4B2\", \"#91D1C2B2\", \"#DC0000B2\", \"#7E6148B2\"\n",
    "    cols = [x.lower() for x in list(cols)]\n",
    "\n",
    "    meta = parse_input()\n",
    "    dd = list(set(meta['COMBO Plasma Box Number']))\n",
    "    meta = meta[meta['COMBO ID'].isin(flt)]\n",
    "    enc = dict(zip(dd, cols))\n",
    "    col_colors = meta['COMBO Plasma Box Number'].map(enc)\n",
    "\n",
    "    col_colors.index = meta['COMBO ID']\n",
    "    meta['COMBO Plasma Box Number'] = pd.Categorical(\n",
    "        meta['COMBO Plasma Box Number'])\n",
    "\n",
    "    meta['TB code'] = pd.Categorical(\n",
    "        meta['TB Classification'])\n",
    "\n",
    "    meta['code'] = meta['COMBO Plasma Box Number'].cat.codes\n",
    "    meta['TB code'] = meta['TB code'].cat.codes\n",
    "    meta.dropna(subset=['TB Classification'], inplace=True)\n",
    "    return meta, col_colors\n",
    "\n",
    "\n",
    "def get_prot_cl(std=True, nmr=False):\n",
    "    X = pd.read_csv('data/protein_level_melted_merged.csv')\n",
    "    X['Pr_gn'] = X['Protein.Group'] + '@' + X['Genes']\n",
    "    X = pd.pivot_table(X, columns='COMBO ID', index='Pr_gn', values='value')\n",
    "    meta, col_colors = preprocess_metadata(list(X))\n",
    "    cls = meta[meta['TB Classification'].isin(['Confirmed TB', 'Unlikely TB'])]\n",
    "    prot_cl = X[list(cls['COMBO ID'])].T\n",
    "    if std:\n",
    "        prot_cl = prot_cl.apply(lambda x: stats.zscore(x), axis=1)\n",
    "    elif nmr: \n",
    "        prot_cl = pd.DataFrame(preprocessing.minmax_scale(prot_cl, feature_range=(0, 1), axis=1, copy=True), index=prot_cl.index, columns=prot_cl.columns)\n",
    "    cls = dict(zip(cls['COMBO ID'], cls['TB Classification']))\n",
    "    y = [cls[x] for x in list(prot_cl.index)]\n",
    "    y = [1 if x == 'Confirmed TB' else 0 for x in y]\n",
    "    return prot_cl, y\n",
    "\n",
    "\n",
    "def get_unconfirmed(std=True, nmr=False):\n",
    "    X = pd.read_csv('data/protein_level_melted_merged.csv')\n",
    "    X['Pr_gn'] = X['Protein.Group'] + '@' + X['Genes']\n",
    "    X = pd.pivot_table(X, columns='COMBO ID', index='Pr_gn', values='value')\n",
    "    meta, col_colors = preprocess_metadata(list(X))\n",
    "\n",
    "    cls = meta[meta['TB Classification'].isin(['Unconfirmed TB'])]\n",
    "    prot_cl = X[list(cls['COMBO ID'])].T\n",
    "    if std:\n",
    "        prot_cl = prot_cl.apply(lambda x: stats.zscore(x), axis=1)\n",
    "    elif nmr: \n",
    "        prot_cl = pd.DataFrame(preprocessing.minmax_scale(prot_cl, feature_range=(0, 1), axis=1, copy=True), index=prot_cl.index, columns=prot_cl.columns)\n",
    "    cls = dict(zip(cls['COMBO ID'], cls['TB Classification']))\n",
    "    y = [cls[x] for x in list(prot_cl.index)]\n",
    "    y = [1 if x == 'Confirmed TB' else 0 for x in y]\n",
    "    return prot_cl, y\n",
    "\n",
    "\n",
    "def get_all(std=True, nmr=False):\n",
    "    X = pd.read_csv('data/protein_level_melted_merged.csv')\n",
    "    X['Pr_gn'] = X['Protein.Group'] + '@' + X['Genes']\n",
    "    X = pd.pivot_table(X, columns='COMBO ID', index='Pr_gn', values='value')\n",
    "    meta, col_colors = preprocess_metadata(list(X))\n",
    "    prot_cl = X[list(meta['COMBO ID'])]\n",
    "    if std:\n",
    "        prot_cl = prot_cl.apply(lambda x: stats.zscore(x), axis=1)\n",
    "    elif nmr: \n",
    "        prot_cl = pd.DataFrame(preprocessing.minmax_scale(prot_cl, feature_range=(0, 1), axis=1, copy=True), index=prot_cl.index, columns=prot_cl.columns)\n",
    "    cls = dict(zip(meta['COMBO ID'], meta['TB Classification']))\n",
    "    prot_cl = pd.melt(prot_cl, ignore_index=False)\n",
    "    prot_cl['tb'] = prot_cl['COMBO ID'].map(cls)\n",
    "    return prot_cl.reset_index()\n",
    "\n",
    "\n",
    "t = 50\n",
    "nanprot = pd.read_csv('new_biosignature/percentage_missing_allproteins_TBClassfiication.csv')\n",
    "nanprot = nanprot[nanprot['TB Classification'].isin(['Confirmed TB', 'Unlikely TB'])]\n",
    "nanprot = nanprot.groupby('Genes').mean(['% miss']).reset_index()\n",
    "nanprot = nanprot[nanprot['% miss']<=t]\n",
    "\n",
    "kk = pd.read_csv('new_biosignature/all_AUC_combined.csv')\n",
    "ll = pd.read_csv('output/allAUC_lasso_6.csv')\n",
    "ll['nfeat'] = 6\n",
    "ll.columns = kk.columns\n",
    "kk = pd.concat([ll, kk], ignore_index=True, axis=0)\n",
    "kk['pr'] = [x.split(',') for x in kk['0']]\n",
    "kk['gn'] = [[item.split('@')[1] for item in sublist] for sublist in kk['pr']]\n",
    "\n",
    "kk['keep'] = [all(gene in nanprot['Genes'].tolist() for gene in x) for x in kk['gn']]\n",
    "kk=kk[kk['keep']==True]\n",
    "#kk2 = kk[(kk['nfeat'] == 6) & (kk['gn'].apply(set) == set(['WARS1', 'APOM', 'CD44', 'TNC', 'AMBP', 'MMP2']))]\n",
    "#kk3 = kk[kk['nfeat'] != 6]\n",
    "#kk = pd.concat([kk2,kk3])\n",
    "kk = kk.loc[kk.groupby('nfeat')['1'].transform(max) == kk['1']]\n",
    "kk = kk.loc[kk.groupby('nfeat')['2'].transform(max) == kk['2']]\n",
    "kk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcab4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add the 1,2\n",
    "\n",
    "for rr in [1,2]:\n",
    "    ll = pd.read_csv('output/allAUC_lasso_{}.csv'.format(str(rr)))\n",
    "    # Select the row with the maximum value in the 'prec70sesn' column\n",
    "    ll = ll[ll['prec70sesn'] == ll['prec70sesn'].max()]\n",
    "    ll = ll[ll['auc'] == ll['auc'].max()]\n",
    "    ll.columns = list(kk)[:ll.shape[1]]\n",
    "    ll['nfeat'] = rr\n",
    "    ll['pr'] = [x.split(',') for x in ll['0']]\n",
    "    ll['gn'] = [[item.split('@')[1] for item in sublist] for sublist in ll['pr']]\n",
    "    ll['keep']=True\n",
    "    kk = pd.concat([kk,ll])\n",
    "    \n",
    "kk.to_csv('new_biosignature/biosignature_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce427c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_auc_manual(nams, save=False):\n",
    "    prot_cl, y = get_prot_cl(True, False)\n",
    "    prot_cl = prot_cl[nams]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        prot_cl, y, random_state=1, stratify=y, test_size=0.25)\n",
    "    clf = LogisticRegression(penalty='l2')\n",
    "    if len(nams)==1:\n",
    "        X_train = X_train.values.reshape(-1,1)\n",
    "        X_test = X_test.values.reshape(-1,1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    if save==True:\n",
    "        joblib.dump(clf, \"new_biosignature/model/model{}.pkl\".format(str(len(nams))))\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    fpr, tpr, thresholds = roc_curve(\n",
    "        y_test, clf.predict_proba(X_test)[:, 1], pos_label=1)\n",
    "    df = pd.DataFrame([fpr, tpr, thresholds]).T\n",
    "    df.columns=['fpr', 'tpr', 'thresh']\n",
    "    df['clf'] = '{} proteins (AUC = {})'.format(\n",
    "        str(len(nams)), auc(fpr, tpr).round(3))\n",
    "    return df\n",
    "\n",
    "\n",
    "tt = []    \n",
    "for _,i in kk.iterrows():\n",
    "    tt.append(test_auc_manual(i['0'].split(','), save=True))\n",
    "    \n",
    "tt = pd.concat(tt)\n",
    "tt.to_csv('new_biosignature/20250411_ROC_CV.csv')\n",
    "\n",
    "\n",
    "### individual features AUC\n",
    "xx = [x for x in kk['0']]\n",
    "k = []\n",
    "for x in xx:\n",
    "    k.extend(x.split(','))\n",
    "tt = []    \n",
    "for i in set(k):\n",
    "    tmp = test_auc_manual([i], save=False)\n",
    "    tmp['clf'] = [x.replace('1 proteins', i.split('@')[-1]) for x in tmp['clf']]\n",
    "    tt.append(tmp)\n",
    "tt = pd.concat(tt)\n",
    "tt.to_csv('new_biosignature/individual_AUC.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocoef = pd.read_csv('output/lassocoef.csv')\n",
    "\n",
    "topn = []\n",
    "for i in range(1,7):\n",
    "    rocdf = test_auc_manual(lassocoef.head(i)['Pr_gn'], save=False)\n",
    "    rocdf['t'] = 'TopN'\n",
    "    rocdf['n'] = i\n",
    "    topn.append(rocdf)\n",
    "\n",
    "topn = pd.concat(topn)\n",
    "tt['n'] = [x.split(' ')[0] for x in tt['clf']]\n",
    "tt['t'] = 'BestN'\n",
    "tot = pd.concat([topn, tt])\n",
    "tot.to_csv('new_biosignature/topN_vs_bestN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "\n",
    "prot_cl, y = get_prot_cl(True, False)\n",
    "thresh = {}\n",
    "for i in range(3,7):\n",
    "    clf = joblib.load('new_biosignature/model/model{}.pkl'.format(str(i)))\n",
    "    print(clf.feature_names_in_)\n",
    "    X_train, X_test, y_train, y_true = train_test_split(\n",
    "    prot_cl[clf.feature_names_in_], y, random_state=1, stratify=y, test_size=0.25)\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "   # Step 1: Find the threshold for 70% specificity\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    specificities = 1 - fpr\n",
    "    # Find the threshold that gives approximately 70% specificity\n",
    "    target_specificity = 0.7\n",
    "    closest_idx = np.argmin(np.abs(specificities - target_specificity))\n",
    "    threshold_for_70_specificity = thresholds[closest_idx]\n",
    "    y_pred_proba = (y_pred_proba >= threshold_for_70_specificity).astype(int)\n",
    "    thresh[i] = threshold_for_70_specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred_proba >= threshold_for_70_specificity).ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn)\n",
    "    sensitivity_ci = proportion_confint(count=tp, nobs=tp + fn, alpha=0.05, method='beta')\n",
    "\n",
    "    # Specificity calculation and 95% CI\n",
    "    specificity = tn / (tn + fp)\n",
    "    specificity_ci = proportion_confint(count=tn, nobs=tn + fp, alpha=0.05, method='beta')\n",
    "\n",
    "    print(sensitivity_ci, specificity_ci)\n",
    "\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d819fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot biosignature across all TB classes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def norm_to_unlikely(grp):\n",
    "    sub = grp[grp['tb']=='Unlikely TB']\n",
    "    grp['value_norm'] = grp['value'] - np.mean(sub['value'].values)\n",
    "    return grp\n",
    "\n",
    "\n",
    "rocv = pd.read_csv('new_biosignature/biosignature_output.csv')\n",
    "rocv = rocv[rocv['nfeat'].isin([5,6])]\n",
    "rocv = [x.split(',') for x in rocv['0']]\n",
    "i = set([x for xs in rocv for x in xs])\n",
    "dd = get_all()\n",
    "i = set([x for xs in rocv for x in xs])\n",
    "dd2 = dd[dd['Pr_gn'].isin(i)]\n",
    "dd2 = dd2.groupby(['Pr_gn']).apply(norm_to_unlikely).reset_index(drop=True)\n",
    "dd2['Pr_gn'] = [x.split('@')[-1] for x in dd2['Pr_gn']]\n",
    "dd2= dd2.groupby(['Pr_gn', 'tb'])['value_norm'].describe()\n",
    "dd2.to_csv('new_biosignature/biosignature_clinical_sites.csv')\n",
    "dd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97164c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "prot_cl = get_all()\n",
    "dd = pd.read_csv('../meta/combo_ms_names_test.csv')\n",
    "dd = dd[dd['TB Classification']=='Unconfirmed TB']\n",
    "prot_cl = prot_cl[prot_cl['COMBO ID'].isin(dd['COMBO ID'])]\n",
    "\n",
    "tt = []\n",
    "preds = []\n",
    "idss = pd.read_csv('new_biosignature/biosignature_output.csv')\n",
    "idss = [x.split(',') for x in list(set(idss['0']))]\n",
    "idss = dict(zip([len(x) for x  in idss], idss))\n",
    "prot_cl = pd.pivot_table(data=prot_cl, columns='Pr_gn', index='COMBO ID', values='value')\n",
    "for i in range(3,7):\n",
    "    clf = joblib.load('new_biosignature/model/model{}.pkl'.format(str(i)))\n",
    "    print(clf.feature_names_in_)\n",
    "    tmp = prot_cl[idss[i]]\n",
    "    ypred = pd.DataFrame(clf.predict_proba(tmp))\n",
    "    ## utilize prediction threshold for reclassifying positive and neg TB\n",
    "    #ypred[0] = [0 if x<=thresh[i] else 1 for x in ypred[1]]\n",
    "    ypred[0] = [0 if x<=0.5 else 1 for x in ypred[1]]\n",
    "    #ypred = pd.DataFrame(clf.predict(tmp))\n",
    "    # print(ypred)\n",
    "    # assert False\n",
    "    ypred['sid'] = prot_cl.index\n",
    "    ypred['cc'] = i\n",
    "    ytot = ypred.groupby([0]).size().to_frame()\n",
    "    ytot['cc'] = '{} feature LR model'.format(i)\n",
    "    tt.append(ytot)\n",
    "    preds.append(ypred)    \n",
    "\n",
    "## re-classify all unconfirmed group\n",
    "\n",
    "tt = pd.concat(tt)\n",
    "ff = pd.concat(preds)\n",
    "ff.columns=['Class', 'LR probability', 'COMBO ID', 'model feature number']\n",
    "ff.to_csv('prediction/pred_model.csv')\n",
    "tt.columns = ['nr', 'cc']\n",
    "## add GS data\n",
    "preds=pd.concat(preds)\n",
    "\n",
    "tt.reset_index(inplace=True)\n",
    "tt[0].replace({0:'Negative', 1:'Positive'}, inplace=True)\n",
    "\n",
    "# #tt[0]=tt[0].\n",
    "#tt\n",
    "\n",
    "preds.to_csv('new_biosignature/individual_prediction.csv')\n",
    "tt.to_csv('new_biosignature/pred_count.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import from_contents, plot\n",
    "from upsetplot import UpSet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "preds[0]= preds[0].replace({0:'Negative', 1:'Positive'})\n",
    "pr_tmp = preds[preds[0]=='Positive']\n",
    "kk = {}\n",
    "for i,grp in pr_tmp.groupby('cc'):\n",
    "    kk[str(i)]=list(grp['sid'])\n",
    "\n",
    "toplot = from_contents(kk)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(2.5, 4))\n",
    "upset = UpSet(toplot, sort_by='cardinality', show_counts=True)  # disable the default bar chart\n",
    "\n",
    "upset.plot(fig=fig)\n",
    "\n",
    "plt.savefig('revision_figures/Fig5_B.pdf', bbox_inches='tight', dpi=800)\n",
    "plt.savefig('revision_figures/Fig5_B.svg', bbox_inches='tight', dpi=800)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee8ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier, NeighborhoodComponentsAnalysis\n",
    "\n",
    "def theme_Publication():\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"paper\", font_scale=1.2)\n",
    "    sns.set_palette(\"colorblind\")\n",
    "    \n",
    "    plt.rcParams[\"font.family\"] = \"Helvetica\"\n",
    "    plt.rcParams[\"figure.figsize\"] = [1.5, 1.5]\n",
    "    plt.rcParams[\"axes.linewidth\"] = 1\n",
    "    plt.rcParams[\"axes.edgecolor\"] = \"black\"\n",
    "    plt.rcParams[\"legend.frameon\"] = False\n",
    "    plt.rcParams[\"legend.loc\"] = \"lower center\"\n",
    "    plt.rcParams[\"legend.framealpha\"] = 1\n",
    "    plt.rcParams[\"legend.fontsize\"] = 9\n",
    "    plt.rcParams[\"legend.title_fontsize\"] = 9\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "    plt.rcParams[\"figure.subplot.left\"] = 0\n",
    "    plt.rcParams[\"figure.subplot.right\"] = 1\n",
    "    plt.rcParams[\"figure.subplot.bottom\"] = 0\n",
    "    plt.rcParams[\"figure.subplot.top\"] = 1\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "tot2 = get_all(False, False)\n",
    "dd = pd.read_csv('../meta/combo_ms_names_test.csv')\n",
    "dd = dd[dd['TB Classification'].isin(['Unconfirmed TB', 'Confirmed TB'])]\n",
    "tot2 = tot2[tot2['COMBO ID'].isin(dd['COMBO ID'])]\n",
    "tmp = tot2[tot2['tb']=='Confirmed TB']\n",
    "z = dict(zip(tmp['COMBO ID'], tmp['tb']))\n",
    "tot2 = pd.pivot_table(data=tot2, columns='Pr_gn', index='COMBO ID', values='value')\n",
    "tt = {}\n",
    "nrmodels = len(set(preds[0]))\n",
    "for i, grp in preds.groupby(['sid']):\n",
    "    tt[i[0]] = str(grp[grp[0]=='Positive'].shape[0])\n",
    "tt.update(z)\n",
    "tot3 = tot2\n",
    "Xarr = StandardScaler(with_mean=True).fit_transform(tot3)\n",
    "\n",
    "clf = LinearDiscriminantAnalysis(solver='svd', n_components=2).fit(Xarr, [tt[i] for i in tot2.index])\n",
    "#print(clf.explained_variance_ratio_)\n",
    "lda_df = clf.transform(Xarr)\n",
    "\n",
    "\n",
    "X_reduced = pd.DataFrame(lda_df)\n",
    "X_reduced['variable'] = tot3.index\n",
    "X_reduced['class'] = X_reduced['variable'].map(tt)\n",
    "X_reduced['class'] = X_reduced['class'].replace({'0':'Negative Unconfirmed', '1': 'Positive 1/4 models', '2': 'Positive 2/4 models', '3': 'Positive 3/4 models', '4': 'Positive all models'})\n",
    "X_reduced['nrfreat'] = str(i)\n",
    "X_reduced.to_csv('new_biosignature/lda_projection.csv')\n",
    "\n",
    "\n",
    "# ## LDA loadings per feature for supplementary\n",
    "lda_loadings = pd.DataFrame(clf.scalings_, index=list(tot3)).reset_index()\n",
    "totfeat = []\n",
    "for i in range(3,7):\n",
    "    clf = joblib.load('new_biosignature/model/model{}.pkl'.format(str(i)))\n",
    "    print(clf.feature_names_in_)\n",
    "    totfeat.extend(clf.feature_names_in_)\n",
    "totfeat = set(totfeat)\n",
    "lda_loadings['biosignature'] = lda_loadings['index'].isin(totfeat)\n",
    "lda_loadings[0] = np.abs(lda_loadings[0])\n",
    "lda_loadings['rank'] = lda_loadings[0].rank(ascending=False)\n",
    "lda_loadings[['Protein', 'Gene']] = lda_loadings['index'].str.split('@', expand=True)\n",
    "lda_loadings.drop(['index'], axis=1, inplace=True)\n",
    "lda_loadings.to_csv('new_biosignature/lda_loadings.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f463056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>variable</th>\n",
       "      <th>class</th>\n",
       "      <th>nrfreat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.458517</td>\n",
       "      <td>0.295461</td>\n",
       "      <td>C138</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.521191</td>\n",
       "      <td>1.437190</td>\n",
       "      <td>C139</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.299973</td>\n",
       "      <td>0.594768</td>\n",
       "      <td>C140</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.715022</td>\n",
       "      <td>-0.306298</td>\n",
       "      <td>C141</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.130670</td>\n",
       "      <td>-1.505676</td>\n",
       "      <td>C142</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-2.768197</td>\n",
       "      <td>-1.088194</td>\n",
       "      <td>C160</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.981232</td>\n",
       "      <td>0.842064</td>\n",
       "      <td>C161</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.569850</td>\n",
       "      <td>1.294248</td>\n",
       "      <td>C162</td>\n",
       "      <td>Latent TB</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.156477</td>\n",
       "      <td>0.416271</td>\n",
       "      <td>C163</td>\n",
       "      <td>Latent TB</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.611727</td>\n",
       "      <td>0.087852</td>\n",
       "      <td>C164</td>\n",
       "      <td>Latent TB</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1 variable      class nrfreat\n",
       "0   0.458517  0.295461     C138    Healthy       3\n",
       "1   0.521191  1.437190     C139    Healthy       3\n",
       "2  -0.299973  0.594768     C140    Healthy       3\n",
       "3  -0.715022 -0.306298     C141    Healthy       3\n",
       "4  -0.130670 -1.505676     C142    Healthy       3\n",
       "..       ...       ...      ...        ...     ...\n",
       "22 -2.768197 -1.088194     C160    Healthy       6\n",
       "23 -1.981232  0.842064     C161    Healthy       6\n",
       "24  0.569850  1.294248     C162  Latent TB       6\n",
       "25 -2.156477  0.416271     C163  Latent TB       6\n",
       "26  0.611727  0.087852     C164  Latent TB       6\n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# biosignature for health and latent TB pca\n",
    "tot2 = get_all(False, False)\n",
    "dd = pd.read_csv('../meta/combo_ms_names_test.csv')\n",
    "dd = dd[dd['TB Classification'].isin(['Latent TB', 'Healthy', ])]\n",
    "tot2 = tot2[tot2['COMBO ID'].isin(dd['COMBO ID'])]\n",
    "tt = dict(zip(tot2['COMBO ID'], tot2['tb']))\n",
    "tot2 = pd.pivot_table(data=tot2, columns='Pr_gn', index='COMBO ID', values='value')\n",
    "\n",
    "test = []\n",
    "for i in range(3,7):\n",
    "    clf = joblib.load('new_biosignature/model/model{}.pkl'.format(str(i)))\n",
    "    tot3 = tot2[clf.feature_names_in_]\n",
    "    Xarr = StandardScaler(with_mean=True).fit_transform(tot3)\n",
    "    pca_df = PCA(n_components=2, svd_solver='full').fit_transform(Xarr)\n",
    "    X_reduced = pd.DataFrame(pca_df)\n",
    "    X_reduced['variable'] = tot2.index\n",
    "    X_reduced['class'] = X_reduced['variable'].map(tt)\n",
    "    X_reduced['nrfreat'] = str(i)\n",
    "    \n",
    "    test.append(X_reduced)\n",
    "   \n",
    "test = pd.concat(test)\n",
    "test.to_csv('new_biosignature/healthy_latent_pca.csv')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
